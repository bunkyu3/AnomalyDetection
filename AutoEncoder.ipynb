{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習用画像作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "def create_train_image():\n",
    "    # 画像サイズ\n",
    "    img_size = (28, 28)\n",
    "    # 矩形のサイズ\n",
    "    rect_size = 20\n",
    "    # 画像の初期化（グレースケールモード）\n",
    "    image = Image.new('L', img_size, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 矩形の左上座標をランダムに決定（矩形が画像内に収まる範囲で）\n",
    "    x = random.randint(0, img_size[0] - rect_size)\n",
    "    y = random.randint(0, img_size[1] - rect_size)\n",
    "    \n",
    "    # 矩形の輝度（160〜200の間からランダムに選択）\n",
    "    brightness = random.randint(160, 255)\n",
    "    \n",
    "    # 矩形を描画\n",
    "    draw.rectangle([x, y, x + rect_size - 1, y + rect_size - 1], fill=brightness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 10枚の画像を生成して保存\n",
    "for i in range(100):\n",
    "    img = create_train_image()\n",
    "    img.save(f\"data/raw/train/{i}_input.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テスト用画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "def create_image(circle_radius):\n",
    "    # 画像サイズ\n",
    "    img_size = (28, 28)\n",
    "    # 矩形のサイズ\n",
    "    rect_size = 20\n",
    "    # 画像の初期化（グレースケールモード）\n",
    "    image = Image.new('L', img_size, 0)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # 矩形の左上座標を画像の中央に設定\n",
    "    x = (img_size[0] - rect_size) // 2\n",
    "    y = (img_size[1] - rect_size) // 2\n",
    "    \n",
    "    # 矩形の輝度（160〜255の間からランダムに選択）\n",
    "    brightness = random.randint(160, 255)\n",
    "    \n",
    "    # 中央に矩形を描画\n",
    "    draw.rectangle([x, y, x + rect_size - 1, y + rect_size - 1], fill=brightness)\n",
    "    \n",
    "    # 円のサイズと位置を計算（矩形の中に中央配置）\n",
    "    circle_x = x + rect_size // 2 - circle_radius\n",
    "    circle_y = y + rect_size // 2 - circle_radius\n",
    "    circle_bbox = [circle_x, circle_y, circle_x + 2 * circle_radius, circle_y + 2 * circle_radius]\n",
    "    \n",
    "    # 矩形の中に輝度0の円を描画\n",
    "    draw.ellipse(circle_bbox, fill=0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 画像を生成して確認\n",
    "image = create_image(10)\n",
    "image.save(\"data/raw/test/0_input.png\")\n",
    "image = create_image(2)\n",
    "image.save(\"data/raw/test/1_input.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSetの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class PngDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(folder_path, f) \n",
    "                            for f in os.listdir(folder_path) \n",
    "                            if f.lower().endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # グレースケールで読み込む\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.flatten(image)\n",
    "        return image\n",
    "\n",
    "folder_path = \"data/raw/train\"\n",
    "dataset = PngDataset(folder_path)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### オートエンコーダによる学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.1447\n",
      "Epoch [2/100], Loss: 0.0919\n",
      "Epoch [3/100], Loss: 0.1071\n",
      "Epoch [4/100], Loss: 0.0987\n",
      "Epoch [5/100], Loss: 0.0897\n",
      "Epoch [6/100], Loss: 0.0865\n",
      "Epoch [7/100], Loss: 0.0894\n",
      "Epoch [8/100], Loss: 0.0720\n",
      "Epoch [9/100], Loss: 0.0446\n",
      "Epoch [10/100], Loss: 0.0391\n",
      "Epoch [11/100], Loss: 0.0379\n",
      "Epoch [12/100], Loss: 0.0268\n",
      "Epoch [13/100], Loss: 0.0305\n",
      "Epoch [14/100], Loss: 0.0249\n",
      "Epoch [15/100], Loss: 0.0244\n",
      "Epoch [16/100], Loss: 0.0208\n",
      "Epoch [17/100], Loss: 0.0188\n",
      "Epoch [18/100], Loss: 0.0200\n",
      "Epoch [19/100], Loss: 0.0178\n",
      "Epoch [20/100], Loss: 0.0182\n",
      "Epoch [21/100], Loss: 0.0167\n",
      "Epoch [22/100], Loss: 0.0181\n",
      "Epoch [23/100], Loss: 0.0195\n",
      "Epoch [24/100], Loss: 0.0148\n",
      "Epoch [25/100], Loss: 0.0144\n",
      "Epoch [26/100], Loss: 0.0155\n",
      "Epoch [27/100], Loss: 0.0179\n",
      "Epoch [28/100], Loss: 0.0140\n",
      "Epoch [29/100], Loss: 0.0166\n",
      "Epoch [30/100], Loss: 0.0165\n",
      "Epoch [31/100], Loss: 0.0149\n",
      "Epoch [32/100], Loss: 0.0106\n",
      "Epoch [33/100], Loss: 0.0115\n",
      "Epoch [34/100], Loss: 0.0129\n",
      "Epoch [35/100], Loss: 0.0138\n",
      "Epoch [36/100], Loss: 0.0125\n",
      "Epoch [37/100], Loss: 0.0098\n",
      "Epoch [38/100], Loss: 0.0117\n",
      "Epoch [39/100], Loss: 0.0150\n",
      "Epoch [40/100], Loss: 0.0139\n",
      "Epoch [41/100], Loss: 0.0112\n",
      "Epoch [42/100], Loss: 0.0105\n",
      "Epoch [43/100], Loss: 0.0127\n",
      "Epoch [44/100], Loss: 0.0105\n",
      "Epoch [45/100], Loss: 0.0128\n",
      "Epoch [46/100], Loss: 0.0112\n",
      "Epoch [47/100], Loss: 0.0124\n",
      "Epoch [48/100], Loss: 0.0105\n",
      "Epoch [49/100], Loss: 0.0113\n",
      "Epoch [50/100], Loss: 0.0087\n",
      "Epoch [51/100], Loss: 0.0101\n",
      "Epoch [52/100], Loss: 0.0087\n",
      "Epoch [53/100], Loss: 0.0108\n",
      "Epoch [54/100], Loss: 0.0110\n",
      "Epoch [55/100], Loss: 0.0098\n",
      "Epoch [56/100], Loss: 0.0072\n",
      "Epoch [57/100], Loss: 0.0106\n",
      "Epoch [58/100], Loss: 0.0091\n",
      "Epoch [59/100], Loss: 0.0106\n",
      "Epoch [60/100], Loss: 0.0108\n",
      "Epoch [61/100], Loss: 0.0104\n",
      "Epoch [62/100], Loss: 0.0103\n",
      "Epoch [63/100], Loss: 0.0084\n",
      "Epoch [64/100], Loss: 0.0148\n",
      "Epoch [65/100], Loss: 0.0096\n",
      "Epoch [66/100], Loss: 0.0117\n",
      "Epoch [67/100], Loss: 0.0107\n",
      "Epoch [68/100], Loss: 0.0075\n",
      "Epoch [69/100], Loss: 0.0082\n",
      "Epoch [70/100], Loss: 0.0071\n",
      "Epoch [71/100], Loss: 0.0101\n",
      "Epoch [72/100], Loss: 0.0085\n",
      "Epoch [73/100], Loss: 0.0070\n",
      "Epoch [74/100], Loss: 0.0098\n",
      "Epoch [75/100], Loss: 0.0070\n",
      "Epoch [76/100], Loss: 0.0055\n",
      "Epoch [77/100], Loss: 0.0066\n",
      "Epoch [78/100], Loss: 0.0064\n",
      "Epoch [79/100], Loss: 0.0094\n",
      "Epoch [80/100], Loss: 0.0066\n",
      "Epoch [81/100], Loss: 0.0069\n",
      "Epoch [82/100], Loss: 0.0080\n",
      "Epoch [83/100], Loss: 0.0078\n",
      "Epoch [84/100], Loss: 0.0062\n",
      "Epoch [85/100], Loss: 0.0099\n",
      "Epoch [86/100], Loss: 0.0067\n",
      "Epoch [87/100], Loss: 0.0060\n",
      "Epoch [88/100], Loss: 0.0052\n",
      "Epoch [89/100], Loss: 0.0056\n",
      "Epoch [90/100], Loss: 0.0066\n",
      "Epoch [91/100], Loss: 0.0095\n",
      "Epoch [92/100], Loss: 0.0055\n",
      "Epoch [93/100], Loss: 0.0060\n",
      "Epoch [94/100], Loss: 0.0072\n",
      "Epoch [95/100], Loss: 0.0079\n",
      "Epoch [96/100], Loss: 0.0054\n",
      "Epoch [97/100], Loss: 0.0061\n",
      "Epoch [98/100], Loss: 0.0047\n",
      "Epoch [99/100], Loss: 0.0056\n",
      "Epoch [100/100], Loss: 0.0081\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "    \n",
    "# 簡単なオートエンコーダモデルの定義\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # エンコーダ部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # デコーダ部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()  # 出力を0～1に制限\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# モデル、損失関数、最適化手法の定義\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習ループ\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for inputs in dataloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)  # 入力と出力の差を計算\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### オートエンコーダによる推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "folder_path = \"data/raw/test\"\n",
    "dataset = PngDataset(folder_path)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "for i, inputs in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(inputs)\n",
    "        inputs_img = inputs[0,:].reshape(28, 28).numpy()\n",
    "        inputs_img = (inputs_img*255).astype(np.uint8)\n",
    "        reconstructed_img = reconstructed[0,:].reshape(28, 28).numpy()\n",
    "        reconstructed_img = (reconstructed_img*255).astype(np.uint8)\n",
    "        diff_img = np.abs(inputs_img.astype(np.int16) - reconstructed_img.astype(np.int16))\n",
    "        diff_img =diff_img.astype(np.uint8)\n",
    "\n",
    "        reconstructed_img = Image.fromarray(reconstructed_img)\n",
    "        reconstructed_img.save(f\"results/{i}_recon.png\")\n",
    "        diff_img = Image.fromarray(diff_img)\n",
    "        diff_img.save(f\"results/{i}_diff.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
